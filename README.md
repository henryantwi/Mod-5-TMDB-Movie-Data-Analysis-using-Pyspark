# ğŸ¬ TMDB Movie Data Analysis Pipeline

A comprehensive data engineering project that extracts, transforms, and analyzes movie data from The Movie Database (TMDB) API using **PySpark**.

![Python](https://img.shields.io/badge/Python-3.14+-blue.svg)
![PySpark](https://img.shields.io/badge/PySpark-4.1+-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [Pipeline Architecture](#-pipeline-architecture)
- [KPI Analysis](#-kpi-analysis)
- [Visualizations](#-visualizations)
- [Output Files](#-output-files)
- [Contributing](#-contributing)

## ğŸ¯ Overview

This project implements a complete **ETL (Extract, Transform, Load)** pipeline for movie data analysis. It fetches movie information from the TMDB API, cleans and transforms the data using PySpark, performs KPI analysis, and generates insightful visualizations.

### What You'll Learn

- How to build a production-ready ETL pipeline
- Working with REST APIs (with retry mechanisms)
- Data cleaning and transformation with PySpark
- KPI calculations and business analytics
- Data visualization with Matplotlib

## âœ¨ Features

### Data Extraction
- ğŸ”„ **Retry Mechanism**: Automatic retries for rate limits and HTTP errors
- ğŸ’¾ **Data Caching**: Cache raw data to avoid repeated API calls
- ğŸ“ **Comprehensive Logging**: All operations logged to file and console

### Data Transformation
- ğŸ§¹ **Data Cleaning**: Handle missing values, invalid data, and duplicates
- ğŸ”„ **Type Conversion**: Proper data types for all columns
- ğŸ’± **Currency Normalization**: Convert budget/revenue to millions USD
- ğŸ“Š **JSON Processing**: Extract nested data from complex columns

### Analysis & Visualization
- ğŸ“ˆ **KPI Rankings**: Top movies by revenue, profit, ROI, rating, and popularity
- ğŸ­ **Franchise Analysis**: Compare franchise vs standalone movie performance
- ğŸ¬ **Director Analysis**: Find most successful directors
- ğŸ“Š **5 Visualization Charts**: Professional annotated charts

## ğŸ“ Project Structure

```
tmdb-movie-analysis/
â”œâ”€â”€ ğŸ“‚ etl/                          # ETL Pipeline Modules
â”‚   â”œâ”€â”€ __init__.py                  # Package initialization
â”‚   â”œâ”€â”€ extract.py                   # TMDB API data extraction
â”‚   â”œâ”€â”€ transform.py                 # Data cleaning & transformation
â”‚   â””â”€â”€ load.py                      # Spark DataFrame operations
â”‚
â”œâ”€â”€ ğŸ“‚ analysis/                     # Analysis Modules
â”‚   â”œâ”€â”€ __init__.py                  # Package initialization
â”‚   â”œâ”€â”€ kpi.py                       # KPI calculations & rankings
â”‚   â””â”€â”€ visualization.py             # Chart generation
â”‚
â”œâ”€â”€ ğŸ“‚ utils/                        # Utility Modules
â”‚   â”œâ”€â”€ __init__.py                  # Package initialization
â”‚   â”œâ”€â”€ config.py                    # Configuration management
â”‚   â””â”€â”€ logger.py                    # Logging setup
â”‚
â”œâ”€â”€ ğŸ“‚ data/                         # Data Storage (git-ignored)
â”‚   â”œâ”€â”€ raw/                         # Raw API responses
â”‚   â””â”€â”€ processed/                   # Cleaned data (Parquet/CSV)
â”‚
â”œâ”€â”€ ğŸ“‚ output/                       # Output Files (git-ignored)
â”‚   â””â”€â”€ visualizations/              # Generated charts
â”‚
â”œâ”€â”€ ğŸ“‚ logs/                         # Log Files (git-ignored)
â”‚
â”œâ”€â”€ main.py                          # Pipeline entry point
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ pyproject.toml                   # Project configuration
â”œâ”€â”€ .env.example                     # Environment template
â”œâ”€â”€ .gitignore                       # Git ignore rules
â””â”€â”€ README.md                        # This file
```

## ğŸš€ Installation

### Prerequisites

- Python 3.14 or higher
- Java 8 or 11 (required for PySpark)
- [uv](https://docs.astral.sh/uv/) package manager (recommended)

### Step-by-Step Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd tmdb-movie-analysis
   ```

2. **Create and activate virtual environment**
   ```bash
   # Using uv (recommended)
   uv venv
   
   # Activate on Windows
   .\.venv\Scripts\Activate.ps1
   
   # Activate on Linux/Mac
   source .venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   uv add -r requirements.txt
   ```

4. **Set up environment variables**
   ```bash
   # Copy the example file
   cp .env.example .env
   
   # Edit .env and add your TMDB API key
   # TMDB_API_KEY=your_api_key_here
   ```

## âš™ï¸ Configuration

### Getting a TMDB API Key

1. Create an account at [TMDB](https://www.themoviedb.org/)
2. Go to Settings â†’ API
3. Request an API key (choose "Developer")
4. Copy your API key to the `.env` file

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `TMDB_API_KEY` | Your TMDB API key | Yes |

## ğŸ’» Usage

### Basic Usage

Run the complete pipeline:

```bash
python main.py
```

### Command Line Options

```bash
# Use cached data (skip API extraction)
python main.py --skip-extract

# Skip visualization generation
python main.py --skip-visualization

# Choose output format
python main.py --output-format csv      # CSV only
python main.py --output-format parquet  # Parquet only (default)
python main.py --output-format all      # All formats

# Combine options
python main.py --skip-extract --output-format all
```

### Help

```bash
python main.py --help
```

## ğŸ”§ Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TMDB Movie Data Pipeline                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ EXTRACT  â”‚â”€â”€â”€â–¶â”‚  TRANSFORM  â”‚â”€â”€â”€â–¶â”‚   LOAD   â”‚â”€â”€â”€â–¶â”‚ ANALYZE â”‚ â”‚
â”‚  â”‚          â”‚    â”‚             â”‚    â”‚          â”‚    â”‚         â”‚ â”‚
â”‚  â”‚ TMDB API â”‚    â”‚  PySpark    â”‚    â”‚ DataFrameâ”‚    â”‚  KPIs   â”‚ â”‚
â”‚  â”‚ + Retry  â”‚    â”‚  Cleaning   â”‚    â”‚ + Save   â”‚    â”‚ + Viz   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â”‚                â”‚                 â”‚               â”‚       â”‚
â”‚       â–¼                â–¼                 â–¼               â–¼       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Raw JSON â”‚    â”‚  Cleaned    â”‚    â”‚ Parquet/ â”‚    â”‚  Charts â”‚ â”‚
â”‚  â”‚  Files   â”‚    â”‚    Data     â”‚    â”‚ CSV/JSON â”‚    â”‚  (PNG)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Extract**: Fetch movie data from TMDB API with retry mechanism
2. **Transform**: Clean, process JSON columns, handle missing values
3. **Load**: Create PySpark DataFrame and save to multiple formats
4. **Analyze**: Calculate KPIs and generate visualizations

## ğŸ“Š KPI Analysis

### Movie Rankings

| Metric | Description |
|--------|-------------|
| Highest Revenue | Top movies by box office earnings |
| Highest Budget | Most expensive productions |
| Highest Profit | Revenue - Budget |
| Highest ROI | Revenue / Budget (min $10M budget) |
| Most Voted | Movies with most user votes |
| Highest Rated | Best ratings (min 10 votes) |
| Most Popular | Highest popularity score |

### Advanced Analysis

- **Franchise vs Standalone**: Compare performance metrics
- **Top Franchises**: Most successful movie franchises
- **Top Directors**: Directors by total revenue and ratings
- **Genre Statistics**: Performance by genre
- **Yearly Trends**: Box office trends over time

### Search Queries

```python
# Search 1: Sci-Fi Action movies with Bruce Willis (sorted by rating)
# Search 2: Uma Thurman + Quentin Tarantino movies (sorted by runtime)
```

## ğŸ“ˆ Visualizations

The pipeline generates 5 professional charts:

1. **Revenue vs Budget** (`revenue_vs_budget.png`)
   - Scatter plot showing the relationship between movie budgets and revenues
   - Point size indicates popularity
   - Break-even line for reference

2. **ROI by Genre** (`roi_by_genre.png`)
   - Horizontal bar chart of mean ROI per genre
   - Color-coded by performance (green=high, red=low)

3. **Popularity vs Rating** (`popularity_vs_rating.png`)
   - Scatter plot revealing quality vs popularity relationship
   - Color intensity shows vote count

4. **Yearly Trends** (`yearly_trends.png`)
   - Line chart showing revenue, budget, and rating trends over time
   - Dual y-axis for financial and rating metrics

5. **Franchise vs Standalone** (`franchise_vs_standalone.png`)
   - Grouped bar chart comparing key metrics
   - Revenue, budget, popularity, and rating comparison

## ğŸ“‚ Output Files

### Data Files

| File | Format | Location |
|------|--------|----------|
| `all_movies_raw.json` | JSON | `data/raw/` |
| `movies_processed/` | Parquet | `data/processed/` |
| `movies_processed.csv/` | CSV | `data/processed/` |
| `movies_processed.json/` | JSON | `data/processed/` |

### Visualization Files

All charts are saved as PNG files in `output/visualizations/`:

- `revenue_vs_budget.png`
- `roi_by_genre.png`
- `popularity_vs_rating.png`
- `yearly_trends.png`
- `franchise_vs_standalone.png`

### Log Files

Detailed logs are saved in `logs/` with timestamps:
- `tmdb_pipeline_YYYYMMDD_HHMMSS.log`

## ğŸ³ Docker Support

You can run the entire pipeline in a Docker container to ensure a consistent environment.

### Prerequisites for Docker
- Docker Desktop installed and running

### Running with Docker Compose (Recommended)

1. **Build and Run**
   ```bash
   docker-compose up --build
   ```

2. **Run in Background**
   ```bash
   docker-compose up -d --build
   ```

3. **View Logs**
   ```bash
   docker-compose logs -f
   ```

4. **Stop Containers**
   ```bash
   docker-compose down
   ```

The pipeline will run, save data to your local `data/` folder, and generate charts in `output/` just like running locally.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [TMDB](https://www.themoviedb.org/) for providing the movie data API
- [PySpark](https://spark.apache.org/docs/latest/api/python/) for distributed data processing
- [Matplotlib](https://matplotlib.org/) for visualization capabilities

---

**Made with â¤ï¸ for Data Engineering**