{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9927bc",
   "metadata": {},
   "source": [
    "# TMDB Movie Analysis Pipeline (PySpark)\n",
    "\n",
    "This notebook orchestrates the complete ETL and analysis pipeline for the TMDB Movie Dataset.\n",
    "It leverages **PySpark** for scalable data processing and **Pandas/Matplotlib** for final visualization.\n",
    "\n",
    "## Pipeline Steps\n",
    "1.  **Fetch**: Retrieve data from TMDB API (with retries and logging).\n",
    "2.  **Process**: Clean and transform JSON data into Parquet using PySpark.\n",
    "3.  **Analyze**: Aggregate and query data using PySpark DSL.\n",
    "4.  **Visualize**: Plot insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d540596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import socketserver\n",
    "from pathlib import Path\n",
    "\n",
    "# --- PySpark on Windows Workaround ---\n",
    "# PySpark 4.x on Windows references UnixStreamServer in accumulators.py \n",
    "# which causes an AttributeError. We patch it to use TCPServer (or a dummy) \n",
    "# to allow the module to import.\n",
    "if os.name == 'nt' and not hasattr(socketserver, 'UnixStreamServer'):\n",
    "    socketserver.UnixStreamServer = socketserver.TCPServer\n",
    "\n",
    "# Add project root to path to allow importing src modules\n",
    "project_root = Path(\"..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import our custom modules\n",
    "from src.logger import setup_logger\n",
    "from src.fetch_data import TMDBFetcher\n",
    "from src.process_data import process_data\n",
    "from src.analysis import MovieAnalyzer\n",
    "\n",
    "# Configure Plotting Style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ce3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Spark in Local Mode: local[*]\n",
      "Data Directory: /home/spark/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/26 11:53:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/01/26 11:54:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Created: TMDB_Movie_Analysis\n",
      "Spark Version: 4.0.1\n"
     ]
    }
   ],
   "source": [
    "# Setup Spark Session\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Add the project root to system path to import modules from src/\n",
    "# In Docker, src is at /home/spark/src, and notebooks are at /home/spark/work\n",
    "sys.path.append('/home/spark') \n",
    "# Fallback for local run if not in Docker structure\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Configuration\n",
    "# Using local[*] mode - runs Spark locally within this container\n",
    "# This is simpler and more stable for development/learning\n",
    "MASTER_URL = \"local[*]\"\n",
    "DATA_DIR = Path(os.getenv(\"DATA_DIR\", \"../data\"))\n",
    "\n",
    "print(f\"Using Spark in Local Mode: {MASTER_URL}\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")\n",
    "\n",
    "# Create SparkSession in local mode\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TMDB_Movie_Analysis\") \\\n",
    "    .master(MASTER_URL) \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark Session Created: {spark.sparkContext.appName}\")\n",
    "print(f\"Spark Version: {spark.version}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b2106",
   "metadata": {},
   "source": [
    "## Step 1: Fetch Data (API)\n",
    "We use the `TMDBFetcher` class to robustly download movie data. This handles retries for rate limits and saves the raw JSON to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fetch_data import TMDBFetcher\n",
    "\n",
    "# Ensure API Key is set\n",
    "# os.environ['TMDB_API_KEY'] = 'your_key_here' # Uncomment and set if not in .env\n",
    "\n",
    "# IDs to fetch\n",
    "movie_ids = [0, 299534, 19995, 140607, 299536, 597, 135397, 420818, 24428, 168259, 99861, 284054, 12445, 181808, 330457, 351286, 109445, 321612, 260513]\n",
    "\n",
    "try:\n",
    "    fetcher = TMDBFetcher()\n",
    "    movies_data = fetcher.fetch_specific_movies(movie_ids)\n",
    "    \n",
    "    raw_output_path = DATA_DIR / \"raw\" / \"movies.json\"\n",
    "    TMDBFetcher.save_raw_data(movies_data, raw_output_path)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b29bcf",
   "metadata": {},
   "source": [
    "## Step 2: Process Data (ETL)\n",
    "We use PySpark to read the nested JSON, flatten it, clean data types, and compute metrics like ROI.\n",
    "The result is saved as a columnar **Parquet** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.process_data import process_data\n",
    "\n",
    "raw_path = str(DATA_DIR / \"raw\" / \"movies.json\")\n",
    "processed_path = str(DATA_DIR / \"processed\" / \"movies.parquet\")\n",
    "\n",
    "try:\n",
    "    process_data(raw_path, processed_path, spark)\n",
    "    print(\"Data processing complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"Processing failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef96be",
   "metadata": {},
   "source": [
    "## Step 3: Analyze Data\n",
    "We initialize the `MovieAnalyzer` which wraps PySpark queries. It computes aggregations on the cluster (simulated) and returns lightweight Pandas DataFrames for results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis import MovieAnalyzer\n",
    "\n",
    "analyzer = MovieAnalyzer(spark)\n",
    "analyzer.load_data(str(DATA_DIR / \"processed\" / \"movies.parquet\"))\n",
    "\n",
    "# 1. Financial Stats\n",
    "financials = analyzer.get_financial_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96dd34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Highest Revenue ---\")\n",
    "print(financials['top_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ab99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Highest Budget ---\")\n",
    "print(financials['top_budget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Highest Profit ---\")\n",
    "print(financials['top_profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ab728",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Lowest Profit (Flops) ---\")\n",
    "print(financials['flops'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa914d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Highest ROI (Budget >= 10M) ---\")\n",
    "print(financials['top_roi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Lowest ROI (Budget >= 10M) ---\")\n",
    "print(financials['flops_roi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc64059",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Most Voted Movies ---\")\n",
    "print(financials['most_voted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9892fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Highest Rated Movies (Votes >= 10) ---\")\n",
    "print(financials['highest_rated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d746f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Highest Rated Movies (Votes >= 10) ---\")\n",
    "print(financials['highest_rated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Lowest Rated Movies (Votes >= 10) ---\")\n",
    "print(financials['lowest_rated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Most Popular Movies ---\")\n",
    "print(financials['most_popular'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ba60d",
   "metadata": {},
   "source": [
    "## Step 4: Visualization\n",
    "Using the aggregated stats from Step 3 to draw insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79490da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Specific Queries\n",
    "specifics = analyzer.get_specific_movies()\n",
    "print(\"\\n--- Bruce Willis Sci-Fi ---\")\n",
    "print(specifics['bruce_willis_scifi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- Uma Thurman & Quentin Tarantino ---\")\n",
    "print(specifics['uma_qt_collab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Franchise Analysis\n",
    "stats, top_franchises = analyzer.analyze_franchises()\n",
    "print(\"\\n--- Franchise Stats ---\")\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc606d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Top Franchises ---\")\n",
    "print(top_franchises)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Top Directors\n",
    "print(\"\\n--- Top Directors ---\")\n",
    "print(analyzer.analyze_directors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_theme(style=\"ticks\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# Fetch Data needed for plots\n",
    "genre_stats = analyzer.get_genre_stats()\n",
    "yearly_stats = analyzer.get_yearly_trends()\n",
    "all_movies = analyzer.get_all_movies_for_plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Revenue vs. Budget (Scatter Plot)\n",
    "plt.figure()\n",
    "sns.scatterplot(data=all_movies, x=\"budget_musd\", y=\"revenue_musd\", size=\"vote_count\", sizes=(20, 500), hue=\"vote_average\", palette=\"viridis\")\n",
    "plt.title(\"Revenue vs. Budget\")\n",
    "plt.xlabel(\"Budget (M$)\")\n",
    "plt.ylabel(\"Revenue (M$)\")\n",
    "plt.plot([0, all_movies['budget_musd'].max()], [0, all_movies['budget_musd'].max()], 'r--', label='Break-even line') # Break-even line\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c336be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. ROI Distribution by Genre (Bar Plot)\n",
    "plt.figure()\n",
    "sns.barplot(data=genre_stats.sort_values(by=\"avg_roi\", ascending=False), x=\"avg_roi\", y=\"genre\", hue=\"genre\", palette=\"viridis\", legend=False)\n",
    "plt.title(\"Average ROI by Genre\")\n",
    "plt.xlabel(\"Average ROI\")\n",
    "plt.ylabel(\"Genre\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35cb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Popularity vs. Rating (Scatter Plot)\n",
    "plt.figure()\n",
    "annotated = sns.scatterplot(data=all_movies, x=\"vote_average\", y=\"popularity\", s=100)\n",
    "plt.title(\"Popularity vs. Rating\")\n",
    "plt.xlabel(\"Vote Average\")\n",
    "plt.ylabel(\"Popularity Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Yearly Box Office Trends (Line Plot)\n",
    "plt.figure()\n",
    "sns.lineplot(data=yearly_stats, x=\"release_year\", y=\"total_revenue\", marker=\"o\", label=\"Revenue\")\n",
    "sns.lineplot(data=yearly_stats, x=\"release_year\", y=\"total_budget\", marker=\"o\", color=\"orange\", label=\"Budget\")\n",
    "plt.title(\"Yearly Box Office Trends\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Amount (M$)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff92d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E. Franchise vs Standalone (Side-by-Side Bar Plot)\n",
    "plt.figure()\n",
    "stats_reset = stats.reset_index()\n",
    "\n",
    "# Melt the dataframe to have Revenue and Budget in one column\n",
    "stats_melted = stats_reset.melt(\n",
    "    id_vars=\"is_franchise\", \n",
    "    value_vars=[\"avg_revenue\", \"avg_budget\"], \n",
    "    var_name=\"Metric\", \n",
    "    value_name=\"Amount (M$)\"\n",
    ")\n",
    "\n",
    "# Rename the metrics for better legend readability\n",
    "stats_melted[\"Metric\"] = stats_melted[\"Metric\"].replace({\n",
    "    \"avg_revenue\": \"Revenue\", \n",
    "    \"avg_budget\": \"Budget\"\n",
    "})\n",
    "\n",
    "# Create grouped bar chart - Swapped x and hue to match the desired layout\n",
    "sns.barplot(data=stats_melted, x=\"Metric\", y=\"Amount (M$)\", hue=\"is_franchise\", palette=\"muted\")\n",
    "\n",
    "plt.title(\"Franchise vs. Standalone: Revenue and Budget Comparison\")\n",
    "plt.ylabel(\"Amount (M$)\")\n",
    "plt.xlabel(\"Metric\")\n",
    "plt.legend(title=\"Franchise Type\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
