{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c62488",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment\n",
    "Install required packages and set up PySpark for Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c0674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# PySpark is the main engine for data processing\n",
    "# tenacity provides retry logic for API calls\n",
    "!pip install pyspark tenacity -q\n",
    "\n",
    "print(\"‚úÖ Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# Retry logic for API calls\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "\n",
    "# PySpark imports for data processing\n",
    "from pyspark.sql import SparkSession, DataFrame, Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, lit, array_join, transform, expr,\n",
    "    to_date, filter as array_filter, element_at,\n",
    "    size, concat_ws, slice as array_slice,\n",
    "    desc, asc, year, count, sum, mean, avg\n",
    ")\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3eed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging for better visibility into what's happening\n",
    "def setup_logger(name: str) -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Creates a logger with console output.\n",
    "    \n",
    "    Args:\n",
    "        name: Name for the logger (usually __name__)\n",
    "    \n",
    "    Returns:\n",
    "        Configured logger instance\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Avoid duplicate handlers if cell is re-run\n",
    "    if not logger.handlers:\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setLevel(logging.INFO)\n",
    "        formatter = logging.Formatter('%(levelname)s: %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "logger = setup_logger(__name__)\n",
    "print(\"‚úÖ Logger configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca14464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è IMPORTANT: Enter your TMDB API key here!\n",
    "# Get your free API key at: https://www.themoviedb.org/settings/api\n",
    "\n",
    "TMDB_API_KEY = \"\"  # <-- Paste your API key between the quotes\n",
    "\n",
    "# Validate the API key is set\n",
    "if not TMDB_API_KEY:\n",
    "    print(\"‚ùå ERROR: Please set your TMDB_API_KEY in the cell above!\")\n",
    "    print(\"   Get a free key at: https://www.themoviedb.org/settings/api\")\n",
    "else:\n",
    "    print(f\"‚úÖ API Key configured (starts with: {TMDB_API_KEY[:4]}...)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e5361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directories for storing raw and processed data\n",
    "DATA_DIR = Path(\"data\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Data directories created:\")\n",
    "print(f\"   Raw data: {RAW_DIR}\")\n",
    "print(f\"   Processed data: {PROCESSED_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cca350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PySpark Session\n",
    "# local[*] means use all available CPU cores\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TMDB_Movie_Analysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Reduce Spark's verbose logging\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(f\"‚úÖ Spark Session Created!\")\n",
    "print(f\"   App Name: {spark.sparkContext.appName}\")\n",
    "print(f\"   Spark Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e6fb66",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Fetch Data from TMDB API\n",
    "\n",
    "We'll fetch movie details including credits (cast & crew) from the TMDB API. The fetcher includes:\n",
    "- **Retry logic** - Automatically retries failed requests\n",
    "- **Rate limiting** - Respects API limits\n",
    "- **Error handling** - Gracefully handles missing movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0439a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMDBFetcher:\n",
    "    \"\"\"\n",
    "    A robust fetcher for TMDB API with retry logic and logging.\n",
    "    Fetches movie details including cast and crew information.\n",
    "    \"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize the fetcher with an API key.\n",
    "        \n",
    "        Args:\n",
    "            api_key: Your TMDB API key\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.logger = setup_logger(\"TMDBFetcher\")\n",
    "        \n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"TMDB_API_KEY is required!\")\n",
    "        \n",
    "        # Use a session for connection pooling (faster)\n",
    "        self.session = requests.Session()\n",
    "\n",
    "    @retry(\n",
    "        stop=stop_after_attempt(5),           # Try up to 5 times\n",
    "        wait=wait_exponential(multiplier=1, min=2, max=10),  # Exponential backoff\n",
    "        retry=retry_if_exception_type((requests.exceptions.RequestException,)),\n",
    "        reraise=True\n",
    "    )\n",
    "    def fetch_movie_details(self, movie_id: int) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Fetch detailed information for a single movie, including credits.\n",
    "        \n",
    "        Args:\n",
    "            movie_id: The TMDB movie ID\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with movie details, or None if not found\n",
    "        \"\"\"\n",
    "        # Append credits to get cast/crew in one request\n",
    "        url = f\"{self.BASE_URL}/movie/{movie_id}?api_key={self.api_key}&append_to_response=credits\"\n",
    "        \n",
    "        response = self.session.get(url, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        elif response.status_code == 404:\n",
    "            self.logger.warning(f\"Movie ID {movie_id} not found.\")\n",
    "            return None\n",
    "        elif response.status_code == 429:\n",
    "            self.logger.warning(\"Rate limited! Waiting before retry...\")\n",
    "            raise requests.exceptions.RequestException(\"Rate limited\")\n",
    "        else:\n",
    "            self.logger.error(f\"Error {response.status_code} for movie {movie_id}\")\n",
    "            response.raise_for_status()\n",
    "\n",
    "    def fetch_multiple_movies(self, movie_ids: List[int]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Fetch details for multiple movies.\n",
    "        \n",
    "        Args:\n",
    "            movie_ids: List of TMDB movie IDs\n",
    "            \n",
    "        Returns:\n",
    "            List of movie detail dictionaries\n",
    "        \"\"\"\n",
    "        movies = []\n",
    "        total = len(movie_ids)\n",
    "        \n",
    "        for i, movie_id in enumerate(movie_ids):\n",
    "            try:\n",
    "                # Skip invalid IDs (like 0)\n",
    "                if movie_id <= 0:\n",
    "                    continue\n",
    "                    \n",
    "                self.logger.info(f\"Fetching movie ID: {movie_id}\")\n",
    "                movie = self.fetch_movie_details(movie_id)\n",
    "                \n",
    "                if movie:\n",
    "                    movies.append(movie)\n",
    "                    \n",
    "                self.logger.info(f\"Progress: {i+1}/{total} completed.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Failed to fetch movie {movie_id}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return movies\n",
    "\n",
    "    @staticmethod\n",
    "    def save_to_json(data: List[Dict], filepath: Path) -> None:\n",
    "        \"\"\"\n",
    "        Save movie data to a JSON file.\n",
    "        \n",
    "        Args:\n",
    "            data: List of movie dictionaries\n",
    "            filepath: Path to save the JSON file\n",
    "        \"\"\"\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"‚úÖ Saved {len(data)} movies to {filepath}\")\n",
    "\n",
    "print(\"‚úÖ TMDBFetcher class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d63f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which movies to fetch\n",
    "# These are popular/high-grossing movie IDs from TMDB\n",
    "MOVIE_IDS = [\n",
    "    299534,  # Avengers: Endgame\n",
    "    19995,   # Avatar\n",
    "    140607,  # Star Wars: The Force Awakens\n",
    "    299536,  # Avengers: Infinity War\n",
    "    597,     # Titanic\n",
    "    135397,  # Jurassic World\n",
    "    420818,  # The Lion King (2019)\n",
    "    24428,   # The Avengers\n",
    "    168259,  # Furious 7\n",
    "    99861,   # Avengers: Age of Ultron\n",
    "    284054,  # Black Panther\n",
    "    12445,   # Harry Potter and the Deathly Hallows Part 2\n",
    "    181808,  # Star Wars: The Last Jedi\n",
    "    330457,  # Frozen II\n",
    "    351286,  # Jurassic World: Fallen Kingdom\n",
    "    109445,  # Frozen\n",
    "    321612,  # Beauty and the Beast (2017)\n",
    "    260513,  # Incredibles 2\n",
    "]\n",
    "\n",
    "print(f\"üìã Will fetch {len(MOVIE_IDS)} movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b585f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch movie data from TMDB API\n",
    "# This cell makes API calls - run only when needed!\n",
    "\n",
    "RAW_FILE = RAW_DIR / \"movies.json\"\n",
    "\n",
    "# Check if we already have the data\n",
    "if RAW_FILE.exists():\n",
    "    print(f\"‚ÑπÔ∏è Raw data already exists at {RAW_FILE}\")\n",
    "    print(\"   Delete the file and re-run to fetch fresh data.\")\n",
    "else:\n",
    "    # Initialize fetcher and download data\n",
    "    fetcher = TMDBFetcher(api_key=TMDB_API_KEY)\n",
    "    movies_data = fetcher.fetch_multiple_movies(MOVIE_IDS)\n",
    "    \n",
    "    # Save to JSON file\n",
    "    TMDBFetcher.save_to_json(movies_data, RAW_FILE)\n",
    "    \n",
    "    print(f\"\\nüé¨ Fetched {len(movies_data)} movies successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcedf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick peek at the raw data structure\n",
    "with open(RAW_FILE, 'r') as f:\n",
    "    sample = json.load(f)\n",
    "\n",
    "print(f\"üìä Raw Data Summary:\")\n",
    "print(f\"   Total movies: {len(sample)}\")\n",
    "print(f\"   Sample movie: {sample[0]['title']}\")\n",
    "print(f\"   Available fields: {list(sample[0].keys())[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140237da",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Process Data with PySpark\n",
    "\n",
    "Transform the raw JSON into a clean, analytics-ready Parquet format:\n",
    "- **Flatten nested structures** (genres, credits, production companies)\n",
    "- **Clean data types** (dates, numbers)\n",
    "- **Calculate metrics** (ROI, profit in millions)\n",
    "- **Extract features** (director, top cast members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f83a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_movie_data(input_path: str, output_path: str, spark: SparkSession) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Process raw movie JSON data into clean Parquet format.\n",
    "    \n",
    "    This function:\n",
    "    1. Loads the raw JSON data\n",
    "    2. Flattens nested structures (genres, credits, etc.)\n",
    "    3. Cleans and converts data types\n",
    "    4. Calculates derived metrics (ROI, profit)\n",
    "    5. Extracts director and cast information\n",
    "    6. Saves as optimized Parquet format\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to raw JSON file\n",
    "        output_path: Path to save Parquet output\n",
    "        spark: Active SparkSession\n",
    "        \n",
    "    Returns:\n",
    "        Processed DataFrame\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading data from {input_path}\")\n",
    "    \n",
    "    # Load JSON (multiline=True because it's a JSON array, not JSON Lines)\n",
    "    df = spark.read.option(\"multiline\", \"true\").json(input_path)\n",
    "    logger.info(f\"Loaded {df.count()} records\")\n",
    "    \n",
    "    # --- STEP 1: Drop irrelevant columns ---\n",
    "    drop_cols = ['adult', 'imdb_id', 'original_title', 'video', 'homepage']\n",
    "    df = df.drop(*drop_cols)\n",
    "    \n",
    "    # --- STEP 2: Flatten nested structures ---\n",
    "    \n",
    "    # Genres: Array<Struct<id, name>> -> \"Action|Adventure|Sci-Fi\"\n",
    "    if \"genres\" in df.columns:\n",
    "        df = df.withColumn(\"genres\", \n",
    "            array_join(transform(\"genres\", lambda x: x[\"name\"]), \"|\"))\n",
    "    \n",
    "    # Collection: Struct<name> -> \"Avengers Collection\"\n",
    "    if \"belongs_to_collection\" in df.columns:\n",
    "        df = df.withColumn(\"belongs_to_collection\", \n",
    "            col(\"belongs_to_collection.name\"))\n",
    "    \n",
    "    # Production info: Array<Struct<name>> -> \"Company1|Company2\"\n",
    "    for c in [\"production_countries\", \"production_companies\", \"spoken_languages\"]:\n",
    "        if c in df.columns:\n",
    "            df = df.withColumn(c, \n",
    "                array_join(transform(c, lambda x: x[\"name\"]), \"|\"))\n",
    "    \n",
    "    # --- STEP 3: Clean numeric columns ---\n",
    "    \n",
    "    # Convert budget/revenue to Double, replace 0 with NULL\n",
    "    for c in [\"budget\", \"revenue\"]:\n",
    "        if c in df.columns:\n",
    "            df = df.withColumn(c, col(c).cast(DoubleType()))\n",
    "            df = df.withColumn(c, when(col(c) == 0, None).otherwise(col(c)))\n",
    "    \n",
    "    # Convert popularity to Double\n",
    "    if \"popularity\" in df.columns:\n",
    "        df = df.withColumn(\"popularity\", col(\"popularity\").cast(DoubleType()))\n",
    "    \n",
    "    # Parse release date\n",
    "    if \"release_date\" in df.columns:\n",
    "        df = df.withColumn(\"release_date\", to_date(col(\"release_date\")))\n",
    "    \n",
    "    # --- STEP 4: Calculate financial metrics ---\n",
    "    \n",
    "    # Budget and Revenue in millions USD (easier to read)\n",
    "    if \"budget\" in df.columns:\n",
    "        df = df.withColumn(\"budget_musd\", col(\"budget\") / 1_000_000)\n",
    "    if \"revenue\" in df.columns:\n",
    "        df = df.withColumn(\"revenue_musd\", col(\"revenue\") / 1_000_000)\n",
    "    \n",
    "    # Profit = Revenue - Budget (in millions)\n",
    "    # ROI = Revenue / Budget (return on investment)\n",
    "    if \"budget_musd\" in df.columns and \"revenue_musd\" in df.columns:\n",
    "        df = df.withColumn(\"profit_musd\", \n",
    "            col(\"revenue_musd\") - col(\"budget_musd\"))\n",
    "        df = df.withColumn(\"roi\", \n",
    "            when(col(\"budget_musd\") > 0, col(\"revenue_musd\") / col(\"budget_musd\"))\n",
    "            .otherwise(0))\n",
    "    \n",
    "    # Drop original budget/revenue (keep the _musd versions)\n",
    "    df = df.drop(\"budget\", \"revenue\")\n",
    "    \n",
    "    # --- STEP 5: Filter data ---\n",
    "    \n",
    "    # Keep only released movies\n",
    "    if \"status\" in df.columns:\n",
    "        df = df.filter(col(\"status\") == \"Released\").drop(\"status\")\n",
    "    \n",
    "    # Remove duplicates and nulls\n",
    "    df = df.dropDuplicates([\"id\"])\n",
    "    df = df.na.drop(subset=[\"id\", \"title\"])\n",
    "    \n",
    "    # --- STEP 6: Extract credits information ---\n",
    "    \n",
    "    if \"credits\" in df.columns:\n",
    "        # Count cast and crew size\n",
    "        df = df.withColumn(\"cast_size\", size(col(\"credits.cast\")))\n",
    "        df = df.withColumn(\"crew_size\", size(col(\"credits.crew\")))\n",
    "        \n",
    "        # Extract director (first crew member with job='Director')\n",
    "        df = df.withColumn(\"director\",\n",
    "            element_at(\n",
    "                transform(\n",
    "                    array_filter(col(\"credits.crew\"), lambda c: c[\"job\"] == \"Director\"),\n",
    "                    lambda x: x[\"name\"]\n",
    "                ),\n",
    "                1  # Get first element\n",
    "            ))\n",
    "        \n",
    "        # Extract top 5 cast members\n",
    "        df = df.withColumn(\"cast\",\n",
    "            array_join(\n",
    "                transform(\n",
    "                    array_slice(col(\"credits.cast\"), 1, 5),\n",
    "                    lambda x: x[\"name\"]\n",
    "                ),\n",
    "                \"|\"\n",
    "            ))\n",
    "        \n",
    "        # Drop the large credits struct\n",
    "        df = df.drop(\"credits\")\n",
    "    \n",
    "    # --- STEP 7: Clean text fields ---\n",
    "    \n",
    "    for c in [\"overview\", \"tagline\"]:\n",
    "        if c in df.columns:\n",
    "            df = df.withColumn(c, \n",
    "                when((col(c) == \"\") | (col(c) == \"No Data\"), None)\n",
    "                .otherwise(col(c)))\n",
    "    \n",
    "    # --- STEP 8: Save as Parquet ---\n",
    "    \n",
    "    logger.info(f\"Writing processed data to {output_path}\")\n",
    "    df.coalesce(1).write.mode(\"overwrite\").parquet(output_path)\n",
    "    logger.info(\"‚úÖ Processing complete!\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ process_movie_data function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the data processing pipeline\n",
    "RAW_PATH = str(RAW_DIR / \"movies.json\")\n",
    "PROCESSED_PATH = str(PROCESSED_DIR / \"movies.parquet\")\n",
    "\n",
    "# Process the data\n",
    "processed_df = process_movie_data(RAW_PATH, PROCESSED_PATH, spark)\n",
    "\n",
    "print(f\"\\nüìä Processed Data Summary:\")\n",
    "print(f\"   Records: {processed_df.count()}\")\n",
    "print(f\"   Columns: {len(processed_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96718ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the schema of processed data\n",
    "print(\"üìã Processed Data Schema:\")\n",
    "processed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725a1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the processed data\n",
    "print(\"üé¨ Sample Processed Movies:\")\n",
    "processed_df.select(\"title\", \"genres\", \"director\", \"budget_musd\", \"revenue_musd\", \"roi\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa788765",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Analyze Data\n",
    "\n",
    "Now let's run analytical queries on our processed data to extract insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec128703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzes movie data using PySpark SQL operations.\n",
    "    Returns results as Pandas DataFrames for easy visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, spark: SparkSession):\n",
    "        \"\"\"\n",
    "        Initialize analyzer with a Spark session.\n",
    "        \n",
    "        Args:\n",
    "            spark: Active SparkSession\n",
    "        \"\"\"\n",
    "        self.spark = spark\n",
    "        self.df: Optional[DataFrame] = None\n",
    "\n",
    "    def load_data(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Load processed Parquet data.\n",
    "        \n",
    "        Args:\n",
    "            path: Path to Parquet file/directory\n",
    "        \"\"\"\n",
    "        logger.info(f\"Loading data from {path}\")\n",
    "        self.df = self.spark.read.parquet(path)\n",
    "        \n",
    "        # Add release year for time-based analysis\n",
    "        if \"release_date\" in self.df.columns:\n",
    "            self.df = self.df.withColumn(\"release_year\", year(col(\"release_date\")))\n",
    "        \n",
    "        # Cache for faster repeated queries\n",
    "        self.df.cache()\n",
    "        logger.info(f\"Loaded {self.df.count()} movies\")\n",
    "\n",
    "    def get_top_by_revenue(self, n: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get top N movies by revenue.\n",
    "        \n",
    "        Args:\n",
    "            n: Number of movies to return\n",
    "            \n",
    "        Returns:\n",
    "            Pandas DataFrame with top movies\n",
    "        \"\"\"\n",
    "        return self.df \\\n",
    "            .select(\"title\", \"revenue_musd\", \"budget_musd\", \"profit_musd\", \"release_year\") \\\n",
    "            .orderBy(desc(\"revenue_musd\")) \\\n",
    "            .limit(n) \\\n",
    "            .toPandas()\n",
    "\n",
    "    def get_top_by_roi(self, n: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get top N movies by return on investment.\n",
    "        \n",
    "        Args:\n",
    "            n: Number of movies to return\n",
    "            \n",
    "        Returns:\n",
    "            Pandas DataFrame with top ROI movies\n",
    "        \"\"\"\n",
    "        return self.df \\\n",
    "            .filter(col(\"roi\") > 0) \\\n",
    "            .select(\"title\", \"roi\", \"budget_musd\", \"revenue_musd\") \\\n",
    "            .orderBy(desc(\"roi\")) \\\n",
    "            .limit(n) \\\n",
    "            .toPandas()\n",
    "\n",
    "    def get_genre_stats(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get average metrics by primary genre.\n",
    "        \n",
    "        Returns:\n",
    "            Pandas DataFrame with genre statistics\n",
    "        \"\"\"\n",
    "        # Extract primary genre (first in the list)\n",
    "        df_with_genre = self.df.withColumn(\n",
    "            \"primary_genre\",\n",
    "            element_at(transform(col(\"genres\"), lambda x: x), 1)\n",
    "        )\n",
    "        \n",
    "        return df_with_genre \\\n",
    "            .groupBy(\"primary_genre\") \\\n",
    "            .agg(\n",
    "                count(\"*\").alias(\"movie_count\"),\n",
    "                avg(\"revenue_musd\").alias(\"avg_revenue_musd\"),\n",
    "                avg(\"budget_musd\").alias(\"avg_budget_musd\"),\n",
    "                avg(\"roi\").alias(\"avg_roi\")\n",
    "            ) \\\n",
    "            .orderBy(desc(\"avg_revenue_musd\")) \\\n",
    "            .toPandas()\n",
    "\n",
    "    def get_director_stats(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get statistics by director.\n",
    "        \n",
    "        Returns:\n",
    "            Pandas DataFrame with director statistics\n",
    "        \"\"\"\n",
    "        return self.df \\\n",
    "            .filter(col(\"director\").isNotNull()) \\\n",
    "            .groupBy(\"director\") \\\n",
    "            .agg(\n",
    "                count(\"*\").alias(\"movie_count\"),\n",
    "                sum(\"revenue_musd\").alias(\"total_revenue_musd\"),\n",
    "                avg(\"roi\").alias(\"avg_roi\")\n",
    "            ) \\\n",
    "            .orderBy(desc(\"total_revenue_musd\")) \\\n",
    "            .toPandas()\n",
    "\n",
    "    def get_franchise_stats(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Analyze movie franchises/collections.\n",
    "        \n",
    "        Returns:\n",
    "            Pandas DataFrame with franchise statistics\n",
    "        \"\"\"\n",
    "        return self.df \\\n",
    "            .filter(col(\"belongs_to_collection\").isNotNull()) \\\n",
    "            .groupBy(\"belongs_to_collection\") \\\n",
    "            .agg(\n",
    "                count(\"*\").alias(\"movie_count\"),\n",
    "                sum(\"revenue_musd\").alias(\"total_revenue_musd\"),\n",
    "                avg(\"roi\").alias(\"avg_roi\")\n",
    "            ) \\\n",
    "            .orderBy(desc(\"total_revenue_musd\")) \\\n",
    "            .toPandas()\n",
    "\n",
    "    def search_by_actor(self, actor_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Find movies featuring a specific actor.\n",
    "        \n",
    "        Args:\n",
    "            actor_name: Name to search for (case-insensitive)\n",
    "            \n",
    "        Returns:\n",
    "            Pandas DataFrame with matching movies\n",
    "        \"\"\"\n",
    "        return self.df \\\n",
    "            .filter(col(\"cast\").contains(actor_name)) \\\n",
    "            .select(\"title\", \"cast\", \"genres\", \"revenue_musd\", \"release_year\") \\\n",
    "            .orderBy(desc(\"revenue_musd\")) \\\n",
    "            .toPandas()\n",
    "\n",
    "print(\"‚úÖ MovieAnalyzer class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65abbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer and load processed data\n",
    "analyzer = MovieAnalyzer(spark)\n",
    "analyzer.load_data(PROCESSED_PATH)\n",
    "\n",
    "print(\"‚úÖ Analyzer ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec464dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 1: Top Movies by Revenue\n",
    "print(\"üí∞ TOP 10 MOVIES BY REVENUE\")\n",
    "print(\"=\" * 60)\n",
    "top_revenue = analyzer.get_top_by_revenue(10)\n",
    "display(top_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 2: Top Movies by ROI (Return on Investment)\n",
    "print(\"üìà TOP 10 MOVIES BY ROI\")\n",
    "print(\"=\" * 60)\n",
    "top_roi = analyzer.get_top_by_roi(10)\n",
    "display(top_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd22f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 3: Director Statistics\n",
    "print(\"üé¨ DIRECTOR STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "director_stats = analyzer.get_director_stats()\n",
    "display(director_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 4: Franchise/Collection Analysis\n",
    "print(\"üé≠ FRANCHISE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "franchise_stats = analyzer.get_franchise_stats()\n",
    "display(franchise_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93317577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 5: Search for movies by actor\n",
    "actor_name = \"Robert Downey Jr.\"  # Try different actors!\n",
    "print(f\"üîç MOVIES FEATURING: {actor_name}\")\n",
    "print(\"=\" * 60)\n",
    "actor_movies = analyzer.search_by_actor(actor_name)\n",
    "display(actor_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520811ed",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Visualizations\n",
    "\n",
    "Create charts to visualize our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18add003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 1: Top 10 Movies by Revenue\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Get data and sort\n",
    "data = top_revenue.sort_values('revenue_musd', ascending=True)\n",
    "\n",
    "# Create horizontal bar chart\n",
    "bars = ax.barh(data['title'], data['revenue_musd'], color='steelblue', edgecolor='navy')\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars, data['revenue_musd']):\n",
    "    ax.text(value + 20, bar.get_y() + bar.get_height()/2, \n",
    "            f'${value:,.0f}M', va='center', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Revenue (Million USD)', fontsize=12)\n",
    "ax.set_title('üé¨ Top 10 Highest-Grossing Movies', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, data['revenue_musd'].max() * 1.15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fefdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 2: Budget vs Revenue Scatter Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Get full dataset as pandas\n",
    "full_df = analyzer.df.select(\"title\", \"budget_musd\", \"revenue_musd\", \"roi\").toPandas()\n",
    "full_df = full_df.dropna()\n",
    "\n",
    "# Create scatter plot\n",
    "scatter = ax.scatter(\n",
    "    full_df['budget_musd'], \n",
    "    full_df['revenue_musd'],\n",
    "    c=full_df['roi'],\n",
    "    cmap='RdYlGn',\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    edgecolors='black'\n",
    ")\n",
    "\n",
    "# Add colorbar for ROI\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('ROI (Revenue/Budget)', fontsize=11)\n",
    "\n",
    "# Add break-even line (revenue = budget)\n",
    "max_val = max(full_df['budget_musd'].max(), full_df['revenue_musd'].max())\n",
    "ax.plot([0, max_val], [0, max_val], 'r--', alpha=0.5, label='Break-even line')\n",
    "\n",
    "# Label some points\n",
    "for _, row in full_df.nlargest(3, 'revenue_musd').iterrows():\n",
    "    ax.annotate(row['title'], (row['budget_musd'], row['revenue_musd']),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Budget (Million USD)', fontsize=12)\n",
    "ax.set_ylabel('Revenue (Million USD)', fontsize=12)\n",
    "ax.set_title('üí∞ Budget vs Revenue (Color = ROI)', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e32c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 3: Franchise Revenue Comparison\n",
    "if len(franchise_stats) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    data = franchise_stats.sort_values('total_revenue_musd', ascending=True)\n",
    "    \n",
    "    colors = plt.cm.viridis(range(0, 256, 256 // len(data)))\n",
    "    bars = ax.barh(data['belongs_to_collection'], data['total_revenue_musd'], color=colors)\n",
    "    \n",
    "    for bar, value in zip(bars, data['total_revenue_musd']):\n",
    "        ax.text(value + 20, bar.get_y() + bar.get_height()/2, \n",
    "                f'${value:,.0f}M', va='center', fontsize=10)\n",
    "    \n",
    "    ax.set_xlabel('Total Revenue (Million USD)', fontsize=12)\n",
    "    ax.set_title('üé≠ Movie Franchise Revenue', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No franchise data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37629e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 4: ROI Distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "roi_data = full_df['roi'].dropna()\n",
    "\n",
    "ax.hist(roi_data, bins=15, color='teal', edgecolor='black', alpha=0.7)\n",
    "ax.axvline(roi_data.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {roi_data.mean():.2f}x')\n",
    "ax.axvline(roi_data.median(), color='orange', linestyle='--', linewidth=2, label=f'Median: {roi_data.median():.2f}x')\n",
    "\n",
    "ax.set_xlabel('ROI (Revenue / Budget)', fontsize=12)\n",
    "ax.set_ylabel('Number of Movies', fontsize=12)\n",
    "ax.set_title('üìä Distribution of Return on Investment', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba82a4a",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated a complete data pipeline using PySpark:\n",
    "\n",
    "1. ‚úÖ **Fetched** movie data from TMDB API with retry logic\n",
    "2. ‚úÖ **Processed** raw JSON into clean Parquet format\n",
    "3. ‚úÖ **Analyzed** data using PySpark SQL operations\n",
    "4. ‚úÖ **Visualized** key insights with Matplotlib\n",
    "\n",
    "### Key Findings:\n",
    "- Top grossing movies are primarily franchises (Avengers, Star Wars)\n",
    "- ROI varies significantly - some lower-budget films outperform blockbusters\n",
    "- Animation and superhero genres dominate box office returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up: Stop Spark session when done\n",
    "# Uncomment to run:\n",
    "# spark.stop()\n",
    "# print(\"‚úÖ Spark session stopped.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
